---
layout: post
title:  "airflow Taskflow API"
date:   2021-04-18 23:00:00 +0800
categories: Airflow
tags: Airflow-Tutorial
excerpt: airflow 2.0
mathjax: true
typora-root-url: ../
---

# airflow Taskflow API

这几天找时间本地装了一下airflow2.0，然后看了一下官方文档，发现2.0一个很重要的更新Taskflow API

而看下来tasklflow api有两个亮点：

1. 对dag跟task做了装饰器，使得代码编辑更简单
2. 原本通过xcom传递数据的隐式依赖，现在得以转变成显式地依赖

## @dag, @task

在2.0之前，我们要定义dag的话需要在代码里定义dag，定义task，也就是说需要用写dag的方式写dag（有点拗口）

然而taskflow api提供了一种task跟dag的封装，让我们可以用通常写代码的方式去写，然后只要加上dag跟task（task现在还只支持pythonoperator的封装）的装饰就好了

例如，dag in airflow 1.*

```python
default_args = {
    'owner': 'airflow',
}
with DAG(
    'tutorial_etl_dag',
    default_args=default_args,
    description='ETL DAG tutorial',
    schedule_interval=None,
    start_date=days_ago(2),
    tags=['example'],
) as dag
```

dag in airflow 2.0

```python
@dag(default_args=default_args, schedule_interval=None, start_date=days_ago(2), tags=['example'])
def tutorial_taskflow_api_etl():
    """
    ### TaskFlow API Tutorial Documentation
    This is a simple ETL data pipeline example which demonstrates the use of
    the TaskFlow API using three simple tasks for Extract, Transform, and Load.
    Documentation that goes along with the Airflow TaskFlow API tutorial is
    located
    [here](https://airflow.apache.org/docs/stable/tutorial_taskflow_api.html)
    """
tutorial_etl_dag = tutorial_taskflow_api_etl()
```

例如，task in airflow 1.*

```python
    def transform(**kwargs):
        ti = kwargs['ti']
        extract_data_string = ti.xcom_pull(task_ids='extract', key='order_data')
        order_data = json.loads(extract_data_string)

        total_order_value = 0
        for value in order_data.values():
            total_order_value += value

        total_value = {"total_order_value": total_order_value}
        total_value_json_string = json.dumps(total_value)
        ti.xcom_push('total_order_value', total_value_json_string)
        
    transform_task = PythonOperator(
        task_id='transform',
        python_callable=transform,
    )
    transform_task.doc_md = """\
#### Transform task
A simple Transform task which takes in the collection of order data from xcom
and computes the total order value.
This computed value is then put into xcom, so that it can be processed by the next task.
"""
```

task in airflow 2.0

```python
    @task(multiple_outputs=True)
    def transform(order_data_dict: dict):
        """
        #### Transform task
        A simple Transform task which takes in the collection of order data and
        computes the total order value.
        """
        total_order_value = 0

        for value in order_data_dict.values():
            total_order_value += value

        return {"total_order_value": total_order_value}
```

## dependency definition

in airflow 1.*

```python
extract_task >> transform_task >> load_task
```

in airflow 2.0

```python
    order_data = extract()
    order_summary = transform(order_data)
    load(order_summary["total_order_value"])
```

我们可以看到在transform这个task中，其实是使用了extract_task中通过xcom传递的数据，而transform_task中处理过的数据也会被用于loadtask，所以我们需要显式地把这个依赖关系在airflow1.*定义出来`extract_task >> transform_task >> load_task`(这种定义依赖关系的方式在2.0也仍然适用)，也就是这个依赖关系是隐含的，需要人去识别的。而在airflow2.0中，只要我们用上面的方式把处理逻辑写下来，airflow就能够识别依赖关系，在图中表达出来。transform返回的total_order_value会被自动push到xcom里去。

### Multiple outputs

默认的，假如有个task返回一个字典{"x": 1, "y": 2}，那么这整个字典会被push到一个xcom里去

我们还可以定义multiple_outputs，让x跟y单独作为两个xcom存储

可以这样

```python
@task
def identity_dict(x: int, y: int) -> Dict[str, int]:
    return {"x": x, "y": y}
```

也可以这样

```python
@task(multiple_outputs=True)
def identity_dict(x: int, y: int):
    return {"x": x, "y": y}
```

# References

[1] [https://airflow.apache.org/docs/apache-airflow/stable/tutorial_taskflow_api.html](https://airflow.apache.org/docs/apache-airflow/stable/tutorial_taskflow_api.html)